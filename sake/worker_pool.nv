/// Worker pool for parallel execution of CPU-intensive tasks
///
/// WorkerPool manages a pool of worker threads that execute
/// CPU-bound tasks in parallel across multiple CPU cores.
///
/// Uses std.worker.Worker.pool() for true multi-threaded parallelism.

use std.worker.Worker;
use std.json;
// Note: worker_context is in same module

/// Worker pool for parallel task execution
///
/// Wraps Worker.pool to provide JSON-based request/response handling
/// for CPU-intensive route handlers.
pub struct SakeWorkerPool {
    /// Number of worker threads (informational, auto-detected by Worker.pool)
    pub size: int,

    /// The underlying worker pool
    pool: WorkerPool<string, string>,
}

impl SakeWorkerPool {
    /// Create a new worker pool
    ///
    /// # Arguments
    /// * `size` - Number of worker threads
    ///
    /// # Returns
    /// New WorkerPool instance
    ///
    /// # Errors
    /// Throws if worker creation fails
    ///
    /// # Example
    /// ```nv
    /// let pool = try SakeWorkerPool.new(4);
    /// ```
    pub fn new(size: int): SakeWorkerPool throws {
        if (size <= 0) {
            throw "Worker pool size must be > 0";
        }

        // Create worker pool with handler function
        // Worker.pool uses CPU count automatically for thread count
        let pool = try Worker.pool(SakeWorkerPool.process_request);

        println(`üç∂ WorkerPool initialized with ${size} threads`);

        return SakeWorkerPool {
            size,
            pool,
        };
    }

    /// Process a request in worker thread
    ///
    /// # Arguments
    /// * `ctx_json` - Serialized WorkerContext as JSON
    ///
    /// # Returns
    /// Serialized WorkerResponse as JSON
    fn process_request(ctx_json: string): string throws {
        // Deserialize context
        let ctx = try WorkerContext.from_json(ctx_json);

        // TODO: Execute actual handler
        // For now, return a simple success response
        // Actual implementation would lookup and execute the registered handler

        let response = WorkerResponse.new(
            200,
            {"Content-Type": "application/json"},
            "{\"status\": \"ok\", \"worker\": true}"
        );

        return try response.to_json();
    }

    /// Submit a task to the worker pool
    ///
    /// # Arguments
    /// * `context_json` - Serialized request context
    /// * `handler_id` - Handler identifier (for future use)
    ///
    /// # Returns
    /// Worker response
    ///
    /// # Errors
    /// Throws if submission or execution fails
    ///
    /// # Example
    /// ```nv
    /// let ctx = WorkerContext.new("/test", "GET", {:}, {:}, {:}, "");
    /// let ctx_json = try ctx.to_json();
    /// let response = try pool.submit(ctx_json, 0);
    /// ```
    pub fn submit(self, context_json: string, handler_id: int): WorkerResponse throws {
        // Execute in worker pool
        let result_json = try self.pool.map(context_json);

        // Deserialize response
        let response = try WorkerResponse.from_json(result_json);
        return response;
    }

    /// Submit multiple tasks in parallel
    ///
    /// # Arguments
    /// * `contexts` - Array of serialized request contexts
    ///
    /// # Returns
    /// Array of worker responses
    pub fn submit_batch(self, contexts: [string]): [WorkerResponse] throws {
        let results = try self.pool.map_array(contexts);

        let responses: [WorkerResponse] = [];
        for (let result_json in results) {
            let response = try WorkerResponse.from_json(result_json);
            responses.push(response);
        }

        return responses;
    }

    /// Shutdown the worker pool
    ///
    /// Note: Worker.pool handles cleanup automatically
    pub fn shutdown(self) {
        println("üç∂ WorkerPool shutdown");
        // Worker.pool handles cleanup automatically
    }
}

// ============================================
// Tests
// ============================================

test "create worker pool" {
    let pool = try! SakeWorkerPool.new(4);
    assert_eq pool.size, 4;
}

test "worker pool validates size" {
    // Test that invalid pool sizes throw errors
    let threw1 = false;
    if (let _ = try? SakeWorkerPool.new(0)) {
        // Should not succeed
    } else {
        threw1 = true;
    }
    assert threw1;

    let threw2 = false;
    if (let _ = try? SakeWorkerPool.new(-1)) {
        // Should not succeed
    } else {
        threw2 = true;
    }
    assert threw2;
}

test "submit task to worker pool" {
    let pool = try! SakeWorkerPool.new(2);

    let ctx = WorkerContext.new(
        "/test",
        "GET",
        {:},
        {:},
        {:},
        ""
    );

    let ctx_json = try! ctx.to_json();

    let response = try! pool.submit(ctx_json, 0);

    assert_eq response.status, 200;
}

test "submit batch to worker pool" {
    let pool = try! SakeWorkerPool.new(2);

    let contexts: [string] = [];
    for (let i in 0..3) {
        let ctx = WorkerContext.new(
            `/test/${i}`,
            "GET",
            {:},
            {:},
            {:},
            ""
        );
        contexts.push(try! ctx.to_json());
    }

    let responses = try! pool.submit_batch(contexts);

    assert_eq responses.len(), 3;
    for (let resp in responses) {
        assert_eq resp.status, 200;
    }
}

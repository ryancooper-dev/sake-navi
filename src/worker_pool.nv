/// Worker pool for parallel execution of CPU-intensive tasks
///
/// WorkerPool manages a pool of worker threads that execute
/// CPU-bound tasks in parallel across multiple CPU cores.
///
/// Uses std.worker.Worker.pool() for true multi-threaded parallelism.

use std.worker.Worker;
use std.json;
use std.sync.freeze;
// Note: worker_context and handler_registry are in same module

// ============================================
// Built-in handlers for Phase 0
// These are defined here so they're available in worker threads
// when the module loads. In Phase 1+, we'll investigate proper
// cross-thread handler registration.
// ============================================

/// CPU-intensive fibonacci computation
fn fibonacci(n: int): int {
    if (n <= 1) {
        return n;
    }
    return fibonacci(n - 1) + fibonacci(n - 2);
}

/// Built-in CPU handler (handler_id = 0)
/// Computes fibonacci for CPU benchmarking
fn builtin_cpu_handler(ctx: WorkerContext): WorkerResponse throws {
    let n_str = ctx.params.get("n") || "30";
    let n = n_str.parse_int() || 30;
    println(`[WORKER] GET ${ctx.path} (n=${n})`);

    if (n > 40) {
        return WorkerResponse.json(400, `{"error": "n too large", "max": 40}`);
    }

    let result = fibonacci(n);
    println(`[WORKER] fibonacci(${n}) = ${result}`);

    return WorkerResponse.json(200, `{"n": ${n}, "result": ${result}, "mode": "worker_pool"}`);
}

// ============================================
// Generic Config type for Frozen<T> testing
// Users can define their own types with matching fields
// ============================================

/// Generic server config for testing Frozen<T> data passing
/// This struct is defined here so it's available in worker threads
pub struct WorkerConfig {
    pub version: string,
    pub message: string,
    pub max_n: int,
}

/// Built-in config handler (handler_id > 0 with frozen "config")
/// Reads Frozen<WorkerConfig> and returns JSON with config values
fn builtin_config_handler(ctx: WorkerContext): WorkerResponse throws {
    // Get frozen config from context
    let config_frozen = try ctx.frozen::<WorkerConfig>("config");
    let config = try config_frozen.get();

    println(`[WORKER] GET ${ctx.path} (version=${config.version})`);

    // Return response using frozen config data
    return WorkerResponse.json(200, `{"message": "${config.message}", "version": "${config.version}", "max_n": ${config.max_n}, "path": "${ctx.path}", "worker": true}`);
}

/// Worker pool for parallel task execution
///
/// Wraps Worker.pool to provide JSON-based request/response handling
/// for CPU-intensive route handlers.
pub struct SakeWorkerPool {
    /// Number of worker threads (informational, auto-detected by Worker.pool)
    pub size: int,

    /// The underlying worker pool
    pool: WorkerPool<string, string>,
}

impl SakeWorkerPool {
    /// Create a new worker pool
    ///
    /// # Arguments
    /// * `size` - Number of worker threads
    ///
    /// # Returns
    /// New WorkerPool instance
    ///
    /// # Errors
    /// Throws if worker creation fails
    ///
    /// # Example
    /// ```nv
    /// let pool = try SakeWorkerPool.new(4);
    /// ```
    pub fn new(size: int): SakeWorkerPool throws {
        if (size <= 0) {
            throw "Worker pool size must be > 0";
        }

        // Create worker pool with handler function
        // Worker.pool uses CPU count automatically for thread count
        let pool = try Worker.pool(SakeWorkerPool.process_request);

        println(`ðŸ¶ WorkerPool initialized with ${size} threads`);

        return SakeWorkerPool {
            size,
            pool,
        };
    }

    /// Process a request in worker thread
    ///
    /// This function is called by Worker.pool() in each worker thread.
    /// It deserializes the WorkerContext, looks up the registered handler
    /// by handler_id, and executes it.
    ///
    /// # Arguments
    /// * `ctx_json` - Serialized WorkerContext as JSON
    ///
    /// # Returns
    /// Serialized WorkerResponse as JSON
    fn process_request(ctx_json: string): string throws {
        // Deserialize context
        let ctx = try WorkerContext.from_json(ctx_json);

        // Phase 0: Use built-in handlers based on handler_id
        // handler_id 0 = CPU-intensive fibonacci handler (for benchmarking)
        // handler_id > 0 = user registered handler (use Frozen data if available)
        // In Phase 1+, we'll implement proper cross-thread handler registration
        if (ctx.handler_id == 0) {
            let response = try builtin_cpu_handler(ctx);
            return try response.to_json();
        }

        // Phase 0: For user-registered handlers (handler_id > 0), call built-in
        // config handler if frozen "config" data is available
        if (ctx.handler_id > 0) {
            // Check if frozen "config" is available
            if (ctx.frozen_data.get("config") != nil) {
                // Use built-in config handler that reads Frozen<WorkerConfig>
                let response = try builtin_config_handler(ctx);
                return try response.to_json();
            }

            // No frozen config, return default worker response
            let response = WorkerResponse.new(
                200,
                {"Content-Type": "application/json"},
                `{"status": "ok", "worker": true, "handler_id": ${ctx.handler_id}, "path": "${ctx.path}"}`
            );
            return try response.to_json();
        }

        // Fallback: handler_id < 0 means no registered handler
        let response = WorkerResponse.new(
            200,
            {"Content-Type": "application/json"},
            `{"status": "ok", "worker": true, "handler": "default", "handler_id": ${ctx.handler_id}}`
        );

        return try response.to_json();
    }

    /// Submit a task to the worker pool
    ///
    /// # Arguments
    /// * `context_json` - Serialized request context
    /// * `handler_id` - Handler identifier (for future use)
    ///
    /// # Returns
    /// Worker response
    ///
    /// # Errors
    /// Throws if submission or execution fails
    ///
    /// # Example
    /// ```nv
    /// let ctx = WorkerContext.new("/test", "GET", {:}, {:}, {:}, "");
    /// let ctx_json = try ctx.to_json();
    /// let response = try pool.submit(ctx_json, 0);
    /// ```
    pub fn submit(self, context_json: string, handler_id: int): WorkerResponse throws {
        // Execute in worker pool
        let result_json = try self.pool.map(context_json);

        // Deserialize response
        let response = try WorkerResponse.from_json(result_json);
        return response;
    }

    /// Submit multiple tasks in parallel
    ///
    /// # Arguments
    /// * `contexts` - Array of serialized request contexts
    ///
    /// # Returns
    /// Array of worker responses
    pub fn submit_batch(self, contexts: [string]): [WorkerResponse] throws {
        let results = try self.pool.map_array(contexts);

        let responses: [WorkerResponse] = [];
        for (let result_json in results) {
            let response = try WorkerResponse.from_json(result_json);
            responses.push(response);
        }

        return responses;
    }

    /// Shutdown the worker pool
    ///
    /// Note: Worker.pool handles cleanup automatically
    pub fn shutdown(self) {
        println("ðŸ¶ WorkerPool shutdown");
        // Worker.pool handles cleanup automatically
    }
}

// ============================================
// Tests
// ============================================

test "create worker pool" {
    let pool = try! SakeWorkerPool.new(4);
    assert_eq pool.size, 4;
}

test "worker pool validates size" {
    // Test that invalid pool sizes throw errors
    let threw1 = false;
    if (let _ = try? SakeWorkerPool.new(0)) {
        // Should not succeed
    } else {
        threw1 = true;
    }
    assert threw1;

    let threw2 = false;
    if (let _ = try? SakeWorkerPool.new(-1)) {
        // Should not succeed
    } else {
        threw2 = true;
    }
    assert threw2;
}

test "submit task to worker pool" {
    let pool = try! SakeWorkerPool.new(2);

    let ctx = WorkerContext.new(
        "/test",
        "GET",
        {:},
        {:},
        {:},
        ""
    );

    let ctx_json = try! ctx.to_json();

    let response = try! pool.submit(ctx_json, 0);

    assert_eq response.status, 200;
}

test "submit batch to worker pool" {
    let pool = try! SakeWorkerPool.new(2);

    let contexts: [string] = [];
    for (let i in 0..3) {
        let ctx = WorkerContext.new(
            `/test/${i}`,
            "GET",
            {:},
            {:},
            {:},
            ""
        );
        contexts.push(try! ctx.to_json());
    }

    let responses = try! pool.submit_batch(contexts);

    assert_eq responses.len(), 3;
    for (let resp in responses) {
        assert_eq resp.status, 200;
    }
}

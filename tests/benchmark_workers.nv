/// Benchmark comparing spawn vs WorkerPool for CPU-bound workload (T023)
///
/// Verifies that WorkerPool achieves 5-7x performance improvement
/// for CPU-intensive routes compared to spawn-only mode.

use std.time;
use std.net.{TcpClient};
use engine.Engine;
use config.Config;
use context.Context;

/// Helper: Make HTTP GET request
fn make_request(port: int, path: string): string throws {
    let client = try TcpClient.connect(`localhost:${port}`);

    defer {
        client.close();
    }

    let request = `GET ${path} HTTP/1.1\r\nHost: localhost\r\nConnection: close\r\n\r\n`;
    try client.write(request.as_bytes());

    let response = try client.read_to_string();
    return response;
}

/// CPU-intensive computation
fn fibonacci(n: int): int {
    if (n <= 1) {
        return n;
    }
    return fibonacci(n - 1) + fibonacci(n - 2);
}

/// Run benchmark for given number of concurrent requests
fn benchmark_mode(use_worker_pool: bool, num_requests: int): float throws {
    let config = Config.default();
    if (!use_worker_pool) {
        config.with_worker_pool(false);
    }

    let app = Engine.new(config);

    let handler = |ctx: Context| {
        // CPU-intensive work
        let result = fibonacci(35);
        try? ctx.json({"result": result});
    };

    if (use_worker_pool) {
        app.get("/compute", handler).worker();
    } else {
        app.get("/compute", handler);
    }

    let port = if (use_worker_pool) { 8895 } else { 8896 };

    spawn {
        try! app.run(`:${port}`);
    }

    time.sleep(0.2.seconds());

    // Run benchmark
    let start = time.now();

    let results_ch = channel::<bool>();

    for (let i in 0..num_requests) {
        spawn {
            let result = try? make_request(port, "/compute");
            try! results_ch.send(result != nil);
        }
    }

    // Wait for all to complete
    for (let i in 0..num_requests) {
        try results_ch.recv();
    }

    let elapsed = time.now() - start;

    return elapsed;
}

test "benchmark spawn vs worker pool" {
    let num_requests = 20;

    println("\nüç∂ Benchmark: Spawn vs WorkerPool");
    println(`Running ${num_requests} concurrent CPU-intensive requests...\n`);

    // Benchmark spawn mode
    println("Testing spawn mode (single-threaded)...");
    let spawn_time = try! benchmark_mode(false, num_requests);
    println(`Spawn mode: ${spawn_time}ms\n`);

    // Benchmark worker pool mode
    println("Testing WorkerPool mode (multi-threaded)...");
    let worker_time = try! benchmark_mode(true, num_requests);
    println(`WorkerPool mode: ${worker_time}ms\n`);

    // Calculate speedup
    let speedup = spawn_time / worker_time;
    println(`Speedup: ${speedup}x\n`);

    // WorkerPool should be significantly faster (target: 5-7x)
    // Allow for some variance in real-world conditions (3x minimum)
    assert speedup >= 3.0;

    if (speedup >= 5.0) {
        println("‚úÖ Achieved target speedup (5x+)!");
    } else {
        println("‚ö†Ô∏è  Below target speedup (5-7x), but still significant improvement");
    }
}
